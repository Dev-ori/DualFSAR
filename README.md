# DualFSAR
AAA740-2024F Final Project

Group 5 : Yongjin Jo, Deok-Hyun Ahn

[Model Architecture](https://excalidraw.com/#json=PhO3qeVFdbYUskLQbfvOZ,dlZytHiHxh44x5rZ9MaiQw)

[drawio](https://drive.google.com/file/d/1hKavgTwDG6Xl5cS8Y8fbL79JM5ip-mii/view?usp=sharing)


# paperReview

Google Scholar 에서, Meta learning + Action recognition으로 검색하여 나온 결과에서
CVPR/ECCV/AAAI/NIPS/IEEE(Journal) + Arxiv 2023~2024로 정리한 논문들입니다.
---
### paper list
---
현재까지 리뷰한 논문/자료의 목록은 아래와 같습니다.

##공통 (리뷰 페이퍼)

- [x] paperReview#0 A Comprehensive Review of Few-shot Action Recognition (Arxiv 2024)
  - [Original Paper Link](https://arxiv.org/pdf/2407.14744)
     
- [ ] paperReview#21 MELTR: Meta Loss Transformer for Learning To Fine-Tune Video Foundation Models (CVPR 2023)
  - [Original Paper Link](https://openaccess.thecvf.com/content/CVPR2023/html/Ko_MELTR_Meta_Loss_Transformer_for_Learning_To_Fine-Tune_Video_Foundation_CVPR_2023_paper.html)

- [ ] paperReview#23 Prompt Learning via Meta-Regularization (CVPR 2024)
  - [Original Paper Link](https://openaccess.thecvf.com/content/CVPR2024/html/Park_Prompt_Learning_via_Meta-Regularization_CVPR_2024_paper.html)
     
##필수 논문 

- [x] **paperReview#7 Semantic-Aware Video Representation for Few-Shot Action Recognition (WACV 2024)**
  - [Original Paper Link](https://openaccess.thecvf.com/content/WACV2024/html/Tang_Semantic-Aware_Video_Representation_for_Few-Shot_Action_Recognition_WACV_2024_paper.html)
  - VideoMAE + CLIP
    
- [ ] paperReview#17 CLIP-guided Prototype Modulating for Few-shot Action Recognition (IJCV 2024)
  - [Original Paper Link](https://prod-files-secure.s3.us-west-2.amazonaws.com/0015e87d-0107-4789-905f-5cfd5c668888/dc52f48f-47c2-47f9-8ab9-3487117e62ad/s11263-023-01917-4.pdf)

- [ ] paperReview#23  FiLM-Ensemble: Probabilistic Deep Learning via Feature-wise Linear Modulation (NIPS2022)
  - [Original Paper Link](https://proceedings.neurips.cc/paper_files/paper/2022/hash/8bd31288ad8e9a31d519fdeede7ee47d-Abstract-Conference.html)
  
- [ ] paperReview#24Temporal FiLM: Capturing Long-Range Sequence Dependencies with Feature-Wise Modulations. (NIPS2019)
  - [Original Paper Link](https://proceedings.neurips.cc/paper/2019/hash/2afc4dfb14e55c6face649a1d0c1025b-Abstract.html)
---
## 선택 (개별 할당)
- [ ] paperReview#1 Unsupervised Few-Shot Action Recognition via Action-Appearance Aligned Meta-Adaptation (ICCV 2021)
  - [Original Paper Link](https://openaccess.thecvf.com/content/ICCV2021/html/Patravali_Unsupervised_Few-Shot_Action_Recognition_via_Action-Appearance_Aligned_Meta-Adaptation_ICCV_2021_paper.html)

- [ ] paperReview#2 Few-Shot Human Motion Prediction via Meta-Learning (ECCV 2018)
  - [Original Paper Link](https://openaccess.thecvf.com/content_ECCV_2018/html/Liangyan_Gui_Few-Shot_Human_Motion_ECCV_2018_paper.html)

- [ ] paperReview#3 Hybrid Relation Guided Set Matching for Few-Shot Action Recognition (CVPR 2022)
  - [Original Paper Link](https://openaccess.thecvf.com/content/CVPR2022/html/Wang_Hybrid_Relation_Guided_Set_Matching_for_Few-Shot_Action_Recognition_CVPR_2022_paper.html)

- [ ] paperReview#4 Temporal-Relational CrossTransformers for Few-Shot Action Recognition (CVPR 2021)
  - [Original Paper Link](https://openaccess.thecvf.com/content/CVPR2021/html/Perrett_Temporal-Relational_CrossTransformers_for_Few-Shot_Action_Recognition_CVPR_2021_paper.html)

- [ ] paperReview#5 TA2N: Two-Stage Action Alignment Network for Few-Shot Action Recognition (AAAI Conference on Artificial Intelligence)
  - [Original Paper Link](https://ojs.aaai.org/index.php/AAAI/article/view/20029)

- [ ] paperReview#6 Joint Attribute and Model Generalization Learning for Privacy-Preserving Action Recognition (NeurIPS 2023)
  - [Original Paper Link](https://proceedings.neurips.cc/paper_files/paper/2023/hash/b762632135b16f1225672f9fe2a9740b-Abstract-Conference.html)


- [ ] paperReview#8 Efficient Few-Shot Action Recognition via Multi-Level Post-Reasoning (ECCV 2024)
  - [Original Paper Link](https://www.ecva.net/papers/eccv_2024/papers_ECCV/papers/00305.pdf)

- [ ] paperReview#9 Active Exploration of Multimodal Complementarity for Few-Shot Action Recognition (CVPR 2023)
  - [Original Paper Link](https://openaccess.thecvf.com/content/CVPR2023/html/Wanyan_Active_Exploration_of_Multimodal_Complementarity_for_Few-Shot_Action_Recognition_CVPR_2023_paper.html)

- [ ] paperReview#10 Task-Aware Dual-Representation Network for Few-Shot Action Recognition
  - [Original Paper Link](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10083098)

- [ ] paperReview#11 MoLo: Motion-Augmented Long-Short Contrastive Learning for Few-Shot Action Recognition (CVPR 2023)
  - [Original Paper Link](https://openaccess.thecvf.com/content/CVPR2023/html/Wang_MoLo_Motion-Augmented_Long-Short_Contrastive_Learning_for_Few-Shot_Action_Recognition_CVPR_2023_paper.html)

- [ ] paperReview#12 Adaptive Local-Component-Aware Graph Convolutional Network for One-Shot Skeleton-Based Action Recognition (WACV 2023)
  - [Original Paper Link](https://openaccess.thecvf.com/content/WACV2023/html/Zhu_Adaptive_Local-Component-Aware_Graph_Convolutional_Network_for_One-Shot_Skeleton-Based_Action_Recognition_WACV_2023_paper.html)

- [ ] paperReview#13 Revisiting the Spatial and Temporal Modeling for Few-Shot Action Recognition (AAAI Conference on Artificial Intelligence)
  - [Original Paper Link](https://ojs.aaai.org/index.php/AAAI/article/view/25403)

- [ ] paperReview#14 Boosting Few-shot Action Recognition with Graph-guided Hybrid Matching (ICCV 2023)
  - [Original Paper Link](https://openaccess.thecvf.com/content/ICCV2023/html/Xing_Boosting_Few-shot_Action_Recognition_with_Graph-guided_Hybrid_Matching_ICCV_2023_paper.html)

- [ ] paperReview#15 Few-Shot Video Classification via Representation Fusion and Promotion Learning (ICCV 2023)
  - [Original Paper Link](https://openaccess.thecvf.com/content/ICCV2023/html/Xia_Few-Shot_Video_Classification_via_Representation_Fusion_and_Promotion_Learning_ICCV_2023_paper.html)

- [ ] paperReview#16 MMG-Ego4D: Multimodal Generalization in Egocentric Action Recognition (CVPR 2023)
  - [Original Paper Link](https://openaccess.thecvf.com/content/CVPR2023/html/Gong_MMG-Ego4D_Multimodal_Generalization_in_Egocentric_Action_Recognition_CVPR_2023_paper.html)


- [ ] paperReview#18 Meta-Reinforcement Learning Based on Self-Supervised Task Representation Learning (AAAI 2023)
  - [Original Paper Link](https://ojs.aaai.org/index.php/AAAI/article/view/26210)

- [ ] paperReview#19 Open Set Action Recognition via Multi-Label Evidential Learning (CVPR 2023)
  - [Original Paper Link](https://openaccess.thecvf.com/content/CVPR2023/papers/Zhao_Open_Set_Action_Recognition_via_Multi-Label_Evidential_Learning_CVPR_2023_paper.pdf)

- [ ] paperReview#20 Two-Stream Temporal Feature Aggregation Based on Clustering for Few-Shot Action Recognition
  - [Original Paper Link](https://ieeexplore.ieee.org/document/10669816)


- [ ] paperReview#22 Meta-Transformer: A Unified Framework for Multimodal Learning
  - [Original Paper Link](https://arxiv.org/abs/2307.10802)
---
### Commit Rules

커밋 규칙은 아래와 같습니다.

`new : 논문 이름` : 읽을 논문 issue 등록  
`add : 논문 이름` : 논문 리뷰 파일(`.md`) 추가 & README 정보 업데이트  

